{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T05:26:24.613205Z",
     "start_time": "2020-05-06T05:18:30.754746Z"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os.path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn import datasets, linear_model, ensemble, neural_network\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T10:25:02.673744Z",
     "start_time": "2020-05-06T10:18:45.858189Z"
    }
   },
   "outputs": [],
   "source": [
    "CONFIG_FILE = '../entsoe-data.config'\n",
    "\n",
    "if not os.path.exists(CONFIG_FILE):\n",
    "    download_dir = input('Path to ENTSO-E data folder: ')\n",
    "    if not os.path.isdir(download_dir):\n",
    "        raise RuntimeError(f'Invalid download_dir, please run cell again: {download_dir}')\n",
    "    with open(CONFIG_FILE, 'w') as f:\n",
    "        f.write(download_dir)\n",
    "else:\n",
    "    with open(CONFIG_FILE) as f:\n",
    "        download_dir = f.read()\n",
    "        \n",
    "# Clear the output after this cell if you want to aovid having your path in the notebook (or execute it twice)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_single_csv_entso_e(file):\n",
    "    return pd.read_csv(file, sep='\\t', encoding='utf-16', parse_dates=[\"DateTime\"])\n",
    "\n",
    "\n",
    "def load_complete_entso_e_data(directory):\n",
    "    pattern = Path(directory) / '*.csv'\n",
    "    files = glob.glob(str(pattern))\n",
    "\n",
    "    if not files:\n",
    "        raise ValueError(f\"No files found when searching in {pattern}, wrong directory?\")\n",
    "    \n",
    "    print(f'Concatenating {len(files)} csv files...')\n",
    "\n",
    "    each_csv_file = [read_single_csv_entso_e(file) for file in files]\n",
    "    data = pd.concat(each_csv_file, ignore_index=True)\n",
    "\n",
    "    data = data.sort_values(by=[\"AreaName\", \"DateTime\"])\n",
    "    data = data.set_index(\"DateTime\")\n",
    "\n",
    "    print(\"Loading done.\")\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "power_demand = load_complete_entso_e_data(download_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hourly_country_data(data, country):\n",
    "    ret_data = data[data[\"AreaName\"] == country].interpolate() # data may contain NAs, therefore inteprolate\n",
    "    ret_data = ret_data.resample(\"1h\").mean().interpolate() # not all hours may be  complete \n",
    "                                                            # (i.e. some last 15 minutes are lacking, therefore another inpolation here)\n",
    "\n",
    "    return ret_data\n",
    "\n",
    "power_demand_at_hourly = get_hourly_country_data(power_demand, \"Austria\")[\"2015-01-01\":\"2019-12-31\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Today's goal\n",
    "\n",
    "We want to understand if electricity load is lower than expected due to the Corona Lockdown. We therefore have to know which electricity load we should have expected without the lockdown.\n",
    "\n",
    "We do so by fitting a function to the electricity load, i.e. $y=f(x_1, x_2, ..., x_n)$. $y$ is the output feature, in our case the load. $f$ is some function depending on some $x_i$. We call the $x_i$ input features in the following.\n",
    "\n",
    "Some useful links\n",
    "- [A very brief introduction to machine learning concepts](https://towardsdatascience.com/introduction-to-machine-learning-for-beginners-eed6024fdb08)\n",
    "- [A more lengthy introduction to machine learning with good visuals](https://www.toptal.com/machine-learning/machine-learning-theory-an-introductory-primer)\n",
    "- [An introduction to machine learning regression algorithms](https://medium.com/datadriveninvestor/regression-in-machine-learning-296caae933ec)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "What could we fit to the load - when you think of the last lecture? Which function could be fit to the model? Which data could be used to describe that function? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put some potential input features here... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do it!\n",
    "\n",
    "We use a Random Forest model for mapping input features to output features. Wanna know what a Random Forest is? [Check this](https://medium.com/@williamkoehrsen/random-forest-simple-explanation-377895a60d2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = power_demand_at_hourly[\"TotalLoadValue\"].values\n",
    "X = power_demand_at_hourly.index.month.values[:, np.newaxis]\n",
    "\n",
    "forest_simple = ensemble.RandomForestRegressor()\n",
    "\n",
    "# Train the model using the training sets\n",
    "forest_simple.fit(X, Y)\n",
    "\n",
    "prediction = forest_simple.predict(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prediction(Y, prediction, alpha=1):\n",
    "    plt.plot(Y, label=\"Observation\")\n",
    "    plt.plot(prediction, label=\"Prediction\", alpha=alpha)\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Load (MW)\")\n",
    "    plt.legend()\n",
    "    \n",
    "plot_prediction(Y, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hm... how could we do even better perhaps?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([power_demand_at_hourly.index.month.values,\n",
    "     power_demand_at_hourly.index.weekday.values,\n",
    "     power_demand_at_hourly.index.hour.values]).T\n",
    "\n",
    "forest_all_time_scales = ensemble.RandomForestRegressor()\n",
    "\n",
    "# Train the model using the training sets\n",
    "forest_all_time_scales.fit(X, Y)\n",
    "\n",
    "predicted = forest_all_time_scales.predict(X)\n",
    "\n",
    "plot_prediction(Y, predicted, alpha=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's zoom in a bit..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prediction(Y[400:500], predicted[400:500])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do it a little bit more correct:\n",
    "you should train your data on a training data set and test it on a test data set.\n",
    "If you do not do that, you may find an extremely good fit, but when you use new data on the algorithm, it may fail!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_training, X_test, Y_training, Y_test = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_split_set = ensemble.RandomForestRegressor()\n",
    "\n",
    "# Train the model using the training sets\n",
    "forest_split_set.fit(X_training, Y_training)\n",
    "\n",
    "prediction = forest_split_set.predict(X_test)\n",
    "\n",
    "plt.plot(Y_test)\n",
    "plt.plot(prediction, alpha=0.5)\n",
    "plt.ylabel(\"Load (MW)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "Why does this figure look different from the other load figures? How else could you plot the data to see if the fit is good?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put some reasons here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do another plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate a quality parameter for the fit..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_training = forest_split_set.predict(X_training)\n",
    "prediction_test = forest_split_set.predict(X_test)\n",
    "\n",
    "print(r2_score(Y_training, prediction_training))\n",
    "print(r2_score(Y_test, prediction_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wowh, that's pretty good. And we are just using time information! That means we have pretty regular data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now redo the model, but instead of months use dayofyear for seasonal adjustment. Calculate R2 if you predict with training data and calculate R2 if you predict with test data. What do you think, is quality improved?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty amazing fit! I think we can work with the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look how this worked for 2020..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_demand_at_hourly_2020 =  get_hourly_country_data(power_demand, \"Austria\")[\"2020-01-01\":\"2020-05-31\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([power_demand_at_hourly.index.dayofyear.values,\n",
    "     power_demand_at_hourly.index.weekday.values,\n",
    "     power_demand_at_hourly.index.hour.values]).T\n",
    "\n",
    "X_training, X_test, Y_training, Y_test = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "forest_dayofyear = ensemble.RandomForestRegressor()\n",
    "\n",
    "# Train the model using the training sets\n",
    "forest_dayofyear.fit(X_training, Y_training)\n",
    "\n",
    "prediction_training = forest_dayofyear.predict(X_training)\n",
    "\n",
    "prediction_test = forest_dayofyear.predict(X_test)\n",
    "\n",
    "print(r2_score(Y_training, prediction_training))\n",
    "print(r2_score(Y_test, prediction_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2020 = np.array([power_demand_at_hourly_2020.index.dayofyear.values,\n",
    "     power_demand_at_hourly_2020.index.weekday.values,\n",
    "     power_demand_at_hourly_2020.index.hour.values]).T\n",
    "\n",
    "prediction_2020 = forest_dayofyear.predict(X_2020)\n",
    "\n",
    "plot_prediction(power_demand_at_hourly_2020[\"TotalLoadValue\"].values, prediction_2020, alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "\n",
    "Calculate the proportion of predicted vs. observed generation on a monthly basis and plot it! Hint: it is easier if you assign a new column to ```power_demand_at_hourly_2020``` with the predicted values from ```pred_2020```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:scientific-computing]",
   "language": "python",
   "name": "conda-env-scientific-computing-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
